{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a7818d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Selenium in e:\\anaconda\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\anaconda\\lib\\site-packages (from Selenium) (0.9.2)"
     ]
    }
   ],
   "source": [
    "# first insatll the selenium library\n",
    "\n",
    "! pip install Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391d0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0efbbd0",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d98d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "#driver=webdriver.Chrome(r\"C:\\Users\\dell 1\\Downloads\\chromedriver_win32/chromedriver.exe\")\n",
    "\n",
    "#request to webpage\n",
    "\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "\n",
    "# enter the skills in search bar\n",
    "\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "\n",
    "# enter the location in search bar\n",
    "\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "# clicking the search button\n",
    "\n",
    "search_btn= driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d5054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "job_title=[]\n",
    "\n",
    "for i in title_tags:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "    \n",
    "#scraping the company names\n",
    "\n",
    "company_tags=driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "company_name=[]\n",
    "\n",
    "for i in company_tags:\n",
    "    name=i.text\n",
    "    company_name.append(name)\n",
    "    \n",
    "    \n",
    "#scraping the location names\n",
    "\n",
    "\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "\n",
    "location=[]\n",
    "\n",
    "for i in location_tags:\n",
    "    loc=i.text\n",
    "    location.append(loc)\n",
    "\n",
    "#scraping the experience\n",
    "\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "\n",
    "experience=[]\n",
    "\n",
    "for i in experience_tags:\n",
    "    exp=i.text\n",
    "    experience.append(exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ed2a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Assistant/deputy Manager - Geo-spatial Data An...</td>\n",
       "      <td>Maruti Suzuki India</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Rapido</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>SYREN TECHNOLOGIES PRIVATE LIMITED</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SENIOR ASSOCIATE ENGINEER - SCM - DATA ANALYST</td>\n",
       "      <td>Collins Aerospace</td>\n",
       "      <td>9-12 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst / Engineer</td>\n",
       "      <td>Animaker India Private Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst (On Contract)</td>\n",
       "      <td>Rupeek Fintech Pvt Ltd</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst for HANA Platform</td>\n",
       "      <td>Intel</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Assistant/deputy Manager - Geo-spatial Data An...   \n",
       "1                                Senior Data Analyst   \n",
       "2                                Senior Data Analyst   \n",
       "3     SENIOR ASSOCIATE ENGINEER - SCM - DATA ANALYST   \n",
       "4                                Senior Data Analyst   \n",
       "5                                       Data Analyst   \n",
       "6                            Data Analyst / Engineer   \n",
       "7                         Data Analyst (On Contract)   \n",
       "8                                Senior Data Analyst   \n",
       "9              Senior Data Analyst for HANA Platform   \n",
       "\n",
       "                                   Company Experience  \\\n",
       "0                      Maruti Suzuki India    3-5 Yrs   \n",
       "1                                   Rapido    1-6 Yrs   \n",
       "2       SYREN TECHNOLOGIES PRIVATE LIMITED   5-10 Yrs   \n",
       "3                        Collins Aerospace   9-12 Yrs   \n",
       "4                                 Flipkart    4-5 Yrs   \n",
       "5  GlaxoSmithKline Pharmaceuticals Limited    3-8 Yrs   \n",
       "6           Animaker India Private Limited    4-9 Yrs   \n",
       "7                   Rupeek Fintech Pvt Ltd    0-2 Yrs   \n",
       "8                                 Flipkart    3-7 Yrs   \n",
       "9                                    Intel   5-10 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                        Gurgaon/Gurugram, bangalore  \n",
       "1                                Bangalore/Bengaluru  \n",
       "2  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bengaluru/Bangalore  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                       Chennai, Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create Dataframe\n",
    "\n",
    "jobs=pd.DataFrame({\"Title\":job_title,\"Company\":company_name,\"Experience\":experience,\"Location\":location})\n",
    "jobs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2962ff",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "461bd725",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#request to webpage\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#driver.close()\n",
    "\n",
    "# enter the skills in search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# enter the location in search bar\n",
    "search_loc=driver.find_element_by_id(\"qsb-location-sugg\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "\n",
    "# clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36612be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "\n",
    "job_title=[] #Create emptylist\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job=i.text\n",
    "    job_title.append(job)\n",
    "\n",
    "#scraping the Location\n",
    "\n",
    "job_loc=[]\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in loc_tags:\n",
    "    loc=i.text\n",
    "    job_loc.append(loc)\n",
    "\n",
    "#scraping the companyname\n",
    "company_name=[]\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "02ceed34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr. Associate Consultant Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Eli Lilly and Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist: Advanced Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cognitive Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Engineer - AIML - Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Unisys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Compile Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cognitive/AI Senior Data Scientist</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Tata Unistore</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title  \\\n",
       "0                    Senior Data Scientist   \n",
       "1  Sr. Associate Consultant Data Scientist   \n",
       "2       Data Scientist: Advanced Analytics   \n",
       "3       Data Scientist: Advanced Analytics   \n",
       "4                 Cognitive Data Scientist   \n",
       "5  Senior Engineer - AIML - Data Scientist   \n",
       "6                    Senior data scientist   \n",
       "7       Cognitive/AI Senior Data Scientist   \n",
       "8         Lead/Senior Data Scientist (NLP)   \n",
       "9                           Data Scientist   \n",
       "\n",
       "                                  Location                    Company  \n",
       "0                      Bangalore/Bengaluru                       Visa  \n",
       "1                      Bangalore/Bengaluru      Eli Lilly and Company  \n",
       "2                      Bengaluru/Bangalore     IBM India Pvt. Limited  \n",
       "3                      Bangalore/Bengaluru     IBM India Pvt. Limited  \n",
       "4                      Bangalore/Bengaluru     IBM India Pvt. Limited  \n",
       "5                      Bangalore/Bengaluru                     Unisys  \n",
       "6                      Bangalore/Bengaluru                Compile Inc  \n",
       "7                      Bengaluru/Bangalore     IBM India Pvt. Limited  \n",
       "8  Bangalore/Bengaluru\\n(WFH during Covid)  Samya.AI A FRACTAL Entity  \n",
       "9              Mumbai, Bangalore/Bengaluru              Tata Unistore  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "job= pd.DataFrame({\"Title\":job_title,\"Location\":job_loc,\"Company\":company_name})\n",
    "job[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ab8df",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "        \n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bba912f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "#request to webpage\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#driver.close()\n",
    "\n",
    "# enter the skills in search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "# clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']\")\n",
    "search_btn.click()\n",
    "\n",
    "\n",
    "#the location filter and salary filter by checking the respective boxes\n",
    "salary=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "salary.click()\n",
    "\n",
    "location= driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "location.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90d54661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping the job-titles\n",
    "\n",
    "job_title=[] #Create emptylist\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job=i.text\n",
    "    job_title.append(job)\n",
    "\n",
    "#scraping the Location\n",
    "\n",
    "job_loc=[]\n",
    "loc_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in loc_tags:\n",
    "    loc=i.text\n",
    "    job_loc.append(loc)\n",
    "\n",
    "#scraping the companyname\n",
    "company_name=[]\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company=i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "#Scraping the experience\n",
    "experience=[]\n",
    "experience_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tag:\n",
    "    exp=i.text\n",
    "    experience.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b433b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...</td>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nodia\\n(WFH during Covid)</td>\n",
       "      <td>Navikenz India Pvt Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Project Manager | Team Leader | Senior Data Sc...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Tidyquant (OPC) Private Limited</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai</td>\n",
       "      <td>Teleperformance</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NTT DATA_ Hiring For BIG DATA ,DATA Scientist,...</td>\n",
       "      <td>Noida, Kolkata, Hyderabad/Secunderabad, Ahmeda...</td>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring For Data Analyst / Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>Careerera</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Whizhack Technologies pvt ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>One Mobikwik Systems Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist/ Senior Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Newgen Software Technologies</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                                     Data Scientist   \n",
       "2                          Hiring For Data Scientist   \n",
       "3  Project Manager | Team Leader | Senior Data Sc...   \n",
       "4                                     Data Scientist   \n",
       "5  NTT DATA_ Hiring For BIG DATA ,DATA Scientist,...   \n",
       "6           Hiring For Data Analyst / Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9              Data Scientist/ Senior Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Noida, New Delhi, Faridabad, Gurgaon/Gurugram,...   \n",
       "1                   Noida, Nodia\\n(WFH during Covid)   \n",
       "2  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "3                                             Remote   \n",
       "4                          Gurgaon/Gurugram, Chennai   \n",
       "5  Noida, Kolkata, Hyderabad/Secunderabad, Ahmeda...   \n",
       "6                             Noida(Sector-59 Noida)   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                                              Noida   \n",
       "\n",
       "                                Company Experience  \n",
       "0        LG Electronics India Pvt. Ltd.    0-2 Yrs  \n",
       "1                Navikenz India Pvt Ltd    2-7 Yrs  \n",
       "2        Tata Consultancy Services Ltd.    4-9 Yrs  \n",
       "3       Tidyquant (OPC) Private Limited    1-5 Yrs  \n",
       "4                       Teleperformance    4-9 Yrs  \n",
       "5   NTT Data Business Solutions Pvt Ltd    3-8 Yrs  \n",
       "6                             Careerera    1-3 Yrs  \n",
       "7         Whizhack Technologies pvt ltd    2-5 Yrs  \n",
       "8  One Mobikwik Systems Private Limited    2-5 Yrs  \n",
       "9          Newgen Software Technologies    2-5 Yrs  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "job= pd.DataFrame({\"Title\":job_title,\"Location\":job_loc,\"Company\":company_name,\"Experience\":experience})\n",
    "job[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7406253",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "ASSIGNMENT 2\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom of the page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9ca553",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "search=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search.send_keys(\"sunglasses\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655b10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae013773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120 120\n"
     ]
    }
   ],
   "source": [
    "search=[]\n",
    "search1=driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "search2=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in search1:\n",
    "    search.append(i.get_attribute('href'))\n",
    "for i in search2:\n",
    "    search.append(i.get_attribute('href'))\n",
    "x=search[0:3]\n",
    "\n",
    "Brand=[] #Create emptylist\n",
    "product_des=[] #Create emptylist\n",
    "price=[] #Create emptylist\n",
    "discount=[] #Create emptylist\n",
    "\n",
    "for page in x:\n",
    "    driver.get(page)\n",
    "    \n",
    "    Brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in Brand_tags:\n",
    "        Brand1=i.text\n",
    "        Brand.append(Brand1)\n",
    "    \n",
    "    des_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa _2-ICcC']\")\n",
    "    for i in Brand_tags:\n",
    "        des=i.text\n",
    "        product_des.append(des)\n",
    " \n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in price_tags:\n",
    "        pri=i.text\n",
    "        price.append(pri)\n",
    "    discount_tags=driver.find_elements_by_xpath(\"//div[@class='_3I9_wc']\")\n",
    "    for i in discount_tags:\n",
    "        dis=i.text\n",
    "        discount.append(dis)\n",
    "    \n",
    "    #search=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav\")\n",
    "    #search.click() \n",
    "    \n",
    "print(len(Brand),len(price),len(discount),len(product_des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84555b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Dicount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>₹999</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>₹299</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹188</td>\n",
       "      <td>₹1,299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹248</td>\n",
       "      <td>₹2,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹187</td>\n",
       "      <td>₹1,599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>GANSTA</td>\n",
       "      <td>₹269</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hipe</td>\n",
       "      <td>hipe</td>\n",
       "      <td>₹189</td>\n",
       "      <td>₹1,298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹664</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>₹759</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brand Product Description Price Dicount\n",
       "0   VINCENT CHASE       VINCENT CHASE  ₹999  ₹1,999\n",
       "1      PHENOMENAL          PHENOMENAL  ₹299  ₹1,999\n",
       "2            SRPM                SRPM  ₹188  ₹1,299\n",
       "3       Elligator           Elligator  ₹248  ₹2,495\n",
       "4          PIRASO              PIRASO  ₹187  ₹1,599\n",
       "..            ...                 ...   ...     ...\n",
       "95      ROYAL SON           ROYAL SON  ₹664  ₹1,999\n",
       "96         GANSTA              GANSTA  ₹269  ₹1,999\n",
       "97           hipe                hipe  ₹189  ₹1,298\n",
       "98      ROYAL SON           ROYAL SON  ₹664  ₹1,999\n",
       "99      ROYAL SON           ROYAL SON  ₹759  ₹1,999\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "job= pd.DataFrame({\"Brand\":Brand,\"Product Description\":product_des,\"Price\":price,\"Dicount\":discount})\n",
    "job[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4903ef7",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/\n",
    "p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8b5a193b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c71b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b33f82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[8]/div/div/div[5]/div/a\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a58c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=[]\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "button_tags=driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "button_tags1=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "\n",
    "for i in button_tags:\n",
    "    next_button.append(i.get_attribute('href'))   \n",
    "for i in button_tags1:\n",
    "    next_button.append(i.get_attribute('href'))\n",
    "    \n",
    "for page in next_button[0:10]:\n",
    "    driver.get(page)\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='col _2wzgFH K0kLPL']/div[1]/div[1]\")\n",
    "    for i in rating_tags:\n",
    "        rating.append(i.text)\n",
    "    \n",
    "    review_tag=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    for i in review_tag:\n",
    "        review_summary.append(i.text)\n",
    "\n",
    "    fullrew_tag=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    for i in fullrew_tag:\n",
    "        full_review.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ce9a4bc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summary</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>Does the job</td>\n",
       "      <td>phone is good but in display is 720p lcd in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5    Terrific purchase   \n",
       "96      5              Awesome   \n",
       "97      3       Decent product   \n",
       "98      5              Awesome   \n",
       "99      3         Does the job   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  I use a Note10+ and have been using both iOS a...  \n",
       "96  The phone is completely good\\nAs far as camera...  \n",
       "97  Everything u ll like it when u use this iPhone...  \n",
       "98  Can’t beat the software and hardware integrati...  \n",
       "99  phone is good but in display is 720p lcd in th...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "job= pd.DataFrame({\"Rating\":rating,\"Review_Summary\":review_summary,\"Full_Review\":full_review})\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c7a62",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "321b5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5d0b68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn=driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4689d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the skills in search bar\n",
    "search_job=driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_job.send_keys(\"sneakers\")\n",
    "\n",
    "# clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "86c6b218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400 400\n"
     ]
    }
   ],
   "source": [
    "# scrape the requird data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "Btn=[]\n",
    "btn1=driver.find_elements_by_xpath(\"//a[@class='ge-49M _2Kfbh8']\")\n",
    "btn2=driver.find_elements_by_xpath(\"//a[@class='ge-49M']\")\n",
    "for i in btn1:\n",
    "    Btn.append(i.get_attribute('href'))\n",
    "for i in btn2:\n",
    "    Btn.append(i.get_attribute('href'))\n",
    "\n",
    "for page in Btn:\n",
    "    driver.get(page)\n",
    "    \n",
    "    brand_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    for i in brand_tags:\n",
    "        brand.append(i.text)\n",
    "    \n",
    "    product_tags=driver.find_elements_by_xpath(\"//div[@class='_2B099V']/a[1]\")\n",
    "    for i in product_tags:\n",
    "        product_description.append(i.text)   \n",
    "     \n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in price_tags:\n",
    "        price.append(i.text) \n",
    "    \n",
    "print(len(brand),len(product_description),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d01bf345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Echor</td>\n",
       "      <td>Men's Canvas Low Top Sneakers Lace-up Classic ...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual Shoes For Men Combo Pack Of 2 Sneakers ...</td>\n",
       "      <td>₹535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Sports Running Shoes Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-496 Sneakers For Men</td>\n",
       "      <td>₹849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 Buck Sneakers For Men</td>\n",
       "      <td>₹1,749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand                                Product_Description   Price\n",
       "0       Echor  Men's Canvas Low Top Sneakers Lace-up Classic ...    ₹449\n",
       "1       BIRDE  Casual Shoes For Men Combo Pack Of 2 Sneakers ...    ₹535\n",
       "2      BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ₹299\n",
       "3    URBANBOX                          Sneakers Sneakers For Men    ₹247\n",
       "4       BIRDE              Sports Running Shoes Sneakers For Men    ₹299\n",
       "..        ...                                                ...     ...\n",
       "395     BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men    ₹423\n",
       "396  RED TAPE                                   Sneakers For Men  ₹1,149\n",
       "397     SPARX                            SM-496 Sneakers For Men    ₹849\n",
       "398     BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men    ₹423\n",
       "399      PUMA                Puma Smash v2 Buck Sneakers For Men  ₹1,749\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "Sneakers= pd.DataFrame({\"Brand\":brand,\"Product_Description\":product_description,\"Price\":price})\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042ee4b",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c55805e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "1a9d5c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "price=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2fcee66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "color=driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "color.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a07c9db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scrape the required data\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "next=[]\n",
    "\n",
    "next_tag=driver.find_elements_by_xpath(\"//li[@class='pagination-active']/a[1]\")\n",
    "next_tag1=driver.find_elements_by_xpath(\"//li[@class='pagination-number']/a[1]\")\n",
    "\n",
    "for i in next_tag:\n",
    "    next.append(i.get_attribute('href'))\n",
    "for i in next_tag1:\n",
    "    next.append(i.get_attribute('href'))\n",
    "\n",
    "for page in next[0:2]:\n",
    "    driver.get(page)\n",
    "    \n",
    "    brand_tag=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    for i in brand_tag:\n",
    "        brand.append(i.text)\n",
    "\n",
    "    description_tag=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    for i in description_tag:\n",
    "        description.append(i.text)\n",
    "        \n",
    "    price_tag=driver.find_elements_by_xpath(\"//div[@class='product-price']/span[1]\")\n",
    "    for i in price_tag:\n",
    "        price.append(i.text)\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a0d950e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Woman Black Leather Boots</td>\n",
       "      <td>Rs. 11250Rs. 12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Women Charged Impulse Shft</td>\n",
       "      <td>Rs. 7499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Leather Boots with Buckles</td>\n",
       "      <td>Rs. 8500Rs. 10500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>PEAKFREAK OUTDRY Trekking Shoe</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Men Solid Leather Formal Penny Loafers</td>\n",
       "      <td>Rs. 7693Rs. 10990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Formal Derbys</td>\n",
       "      <td>Rs. 6299Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Leather Slip-On Shoes</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                     Product_Description  \\\n",
       "0              J.FONTINI         Men Solid Leather Formal Derbys   \n",
       "1                Saint G               Woman Black Leather Boots   \n",
       "2           UNDER ARMOUR              Women Charged Impulse Shft   \n",
       "3                Saint G              Leather Boots with Buckles   \n",
       "4               Columbia          PEAKFREAK OUTDRY Trekking Shoe   \n",
       "..                   ...                                     ...   \n",
       "95  Heel & Buckle London  Men Solid Leather Formal Penny Loafers   \n",
       "96          Hush Puppies               Men Leather Formal Derbys   \n",
       "97                 Ruosh               Men Leather Slip-On Shoes   \n",
       "98             J.FONTINI              Men Leather Formal Loafers   \n",
       "99             J.FONTINI         Men Solid Leather Formal Derbys   \n",
       "\n",
       "                 Price  \n",
       "0             Rs. 6990  \n",
       "1   Rs. 11250Rs. 12500  \n",
       "2             Rs. 7499  \n",
       "3    Rs. 8500Rs. 10500  \n",
       "4             Rs. 9999  \n",
       "..                 ...  \n",
       "95   Rs. 7693Rs. 10990  \n",
       "96    Rs. 6299Rs. 6999  \n",
       "97            Rs. 6990  \n",
       "98            Rs. 6990  \n",
       "99            Rs. 6990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Shoe= pd.DataFrame({\"Brand\":brand,\"Product_Description\":description,\"Price\":price})\n",
    "Shoe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1135dc2",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "As shown in the below image as the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "94595d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "27201c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.amazon.in/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "9e0f7419",
   "metadata": {},
   "outputs": [],
   "source": [
    "search= driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "76460ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "click1=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "click1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "620a1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "corei7=driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[6]/ul[1]/li[12]/span/a/span\")\n",
    "corei7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "33fa6864",
   "metadata": {},
   "outputs": [],
   "source": [
    "titile=[]\n",
    "price=[]\n",
    "#scrape Title\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in title_tags[0:10]:\n",
    "    titile.append(i.text)\n",
    "\n",
    "# scrape Price\n",
    "price_tags=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in price_tags[0:10]:\n",
    "    price.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "c606983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape rating\n",
    "rating=[]\n",
    "rating1=[]\n",
    "rating_tags=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "for i in rating_tags:\n",
    "    rating.append(i.get_attribute('href'))\n",
    "\n",
    "for i in rating[0:10]:\n",
    "    driver.get(i)\n",
    "    \n",
    "    rating1_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "    for i in rating1_tags:\n",
    "        rating1.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "dd7e89b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Gram 16 Ultra-Light Intel Evo 11th Gen Core...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>94,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...</td>\n",
       "      <td>3.6 out of 5</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>54,498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>52,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mi Notebook Pro QHD+ IPS Anti Glare Display In...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>73,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>85,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion (2021) Intel 11th Gen Core i7 14 i...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi Notebook Ultra 3.2K resolution display Inte...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>77,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Gaming(2021) 10th Gen Intel Core i...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>88,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Gaming 3 11th Gen Intel Core i7...</td>\n",
       "      <td>4.9 out of 5</td>\n",
       "      <td>82,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating   Price\n",
       "0  LG Gram 16 Ultra-Light Intel Evo 11th Gen Core...  4.2 out of 5  94,499\n",
       "1  Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...  3.6 out of 5  89,990\n",
       "2  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.4 out of 5  54,498\n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5  52,999\n",
       "4  Mi Notebook Pro QHD+ IPS Anti Glare Display In...  4.3 out of 5  73,999\n",
       "5  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....  4.3 out of 5  85,990\n",
       "6  HP Pavilion (2021) Intel 11th Gen Core i7 14 i...  4.3 out of 5  84,990\n",
       "7  Mi Notebook Ultra 3.2K resolution display Inte...  4.3 out of 5  77,999\n",
       "8  HP Pavilion Gaming(2021) 10th Gen Intel Core i...    4 out of 5  88,999\n",
       "9  Lenovo IdeaPad Gaming 3 11th Gen Intel Core i7...  4.9 out of 5  82,990"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crate Dataframe\n",
    "laptop= pd.DataFrame({\"Title\":titile,\"Rating\":rating1,\"Price\":price})\n",
    "laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3f661",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "be90fb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.ambitionbox.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#click on Job\n",
    "job=driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "job.click()\n",
    "\n",
    "#Enter the job Title\n",
    "search_title=driver.find_element_by_xpath(\"//input[@class='input tt-input']\")\n",
    "search_title.send_keys(\"Data Scientist\")\n",
    "\n",
    "#click on search Button\n",
    "search_btn=driver.find_element_by_xpath(\"//button[@class='ab_btn search-btn round']\")\n",
    "search_btn.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a42db877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the location\n",
    "search_loc=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/p\")\n",
    "search_loc.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3a44f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the location name\n",
    "search_loc1=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "search_loc1.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "eca13e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on the location\n",
    "search_noida=driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "search_noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0aa6c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape Company Name\n",
    "company=[]\n",
    "company_tags=driver.find_elements_by_xpath(\"//p[@class='company body-medium']\")\n",
    "for i in company_tags:\n",
    "    company.append(i.text)\n",
    "\n",
    "#scrape post dayago\n",
    "dayago=[]\n",
    "dayago_tags=driver.find_elements_by_xpath(\"//div[@class='other-info']/Span[1]\")\n",
    "for i in dayago_tags:\n",
    "    dayago.append(i.text)\n",
    "\n",
    "#Scrape Rating\n",
    "rating=[]\n",
    "rating_tags=driver.find_elements_by_xpath(\"//div[@class='rating-wrapper']/a[1]\")\n",
    "for i in rating_tags[1:11]:\n",
    "    rating.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "95d50843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Dayago</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>10d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>16d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NTT Data Business Solutions Pvt Ltd</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Steria India Ltd</td>\n",
       "      <td>1mon ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Company    Dayago Rating\n",
       "0       LG Electronics India Pvt. Ltd.   10d ago    4.1\n",
       "1        GENPACT India Private Limited   16d ago    4.0\n",
       "2        GENPACT India Private Limited   16d ago    4.0\n",
       "3  NTT Data Business Solutions Pvt Ltd   18d ago    3.8\n",
       "4        GENPACT India Private Limited   18d ago    4.0\n",
       "5                                Paytm    3d ago    3.7\n",
       "6                             GI Group    3d ago    4.0\n",
       "7                             GI Group    3d ago    4.0\n",
       "8                             GI Group    3d ago    4.0\n",
       "9                     Steria India Ltd  1mon ago    4.1"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create DataFrame\n",
    "job= pd.DataFrame({\"Company\":company,\"Dayago\":dayago,\"Rating\":rating})\n",
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7efde",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a3cfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "url=\"https://www.ambitionbox.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "#click on Salary\n",
    "salary=driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\").click()\n",
    "\n",
    "#enter job Title\n",
    "job_search=driver.find_element_by_id(\"jobProfileSearchbox\")\n",
    "job_search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e5f9357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_click=driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]\")\n",
    "job_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d029c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#company Title\n",
    "title=[]\n",
    "title1=driver.find_elements_by_xpath(\"//div[@class='name']/a[1]\")\n",
    "for i in title1:\n",
    "    title.append(i.text)\n",
    "\n",
    "#Number of salary\n",
    "nosalary=[]\n",
    "nosalary_tags=driver.find_elements_by_xpath(\"//div[@class='name']/span[1]\")\n",
    "for i in nosalary_tags:\n",
    "    nosalary.append(i.text)\n",
    "\n",
    "#Experince Level\n",
    "exp=[]\n",
    "exp_tags=driver.find_elements_by_xpath(\"//div[@class='salaries sbold-list-header']\")\n",
    "for i in exp_tags:\n",
    "    exp.append(i.text.split('.')[1].replace(\"\\n\",\"\"))\n",
    "\n",
    "#min of Salary    \n",
    "minsalary=[]\n",
    "minsalary_tags=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[1]\")\n",
    "for i in minsalary_tags:\n",
    "    minsalary.append(i.text)\n",
    "\n",
    "#max of Salary\n",
    "maxsalary=[]\n",
    "maxsalary_tags=driver.find_elements_by_xpath(\"//div[@class='salary-values']/div[2]\")\n",
    "for i in maxsalary_tags:\n",
    "    maxsalary.append(i.text)\n",
    "\n",
    "#average of Salary\n",
    "avgsalary=[]\n",
    "avgsalary_tags=driver.find_elements_by_xpath(\"//p[@class='averageCtc']\")\n",
    "for i in avgsalary_tags:\n",
    "    avgsalary.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "95024099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>NoSalary</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Minmum_Salary</th>\n",
       "      <th>Maxmium_Salary</th>\n",
       "      <th>Average_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 20 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 19.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 12 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 15.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 66 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 47 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 26 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 5.2L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "      <td>₹ 11.7L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Deloitte</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 6.8L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 11.2L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Title              NoSalary    Experience Minmum_Salary  \\\n",
       "0                  Ab Inbev  based on 20 salaries   3-4 yrs exp       ₹ 15.0L   \n",
       "1                        ZS  based on 12 salaries     2 yrs exp        ₹ 9.8L   \n",
       "2                     Optum  based on 23 salaries   3-4 yrs exp       ₹ 11.0L   \n",
       "3         Fractal Analytics  based on 66 salaries   2-4 yrs exp        ₹ 9.5L   \n",
       "4              UnitedHealth  based on 47 salaries   2-4 yrs exp        ₹ 7.2L   \n",
       "5           Tiger Analytics  based on 26 salaries   3-4 yrs exp        ₹ 8.3L   \n",
       "6                   Verizon  based on 14 salaries     4 yrs exp       ₹ 10.0L   \n",
       "7  Ganit Business Solutions  based on 13 salaries     4 yrs exp        ₹ 8.5L   \n",
       "8                  Ericsson  based on 42 salaries   3-4 yrs exp        ₹ 5.2L   \n",
       "9                  Deloitte  based on 49 salaries   2-4 yrs exp        ₹ 6.8L   \n",
       "\n",
       "  Maxmium_Salary Average_Salary  \n",
       "0        ₹ 23.0L        ₹ 19.0L  \n",
       "1        ₹ 19.5L        ₹ 15.3L  \n",
       "2        ₹ 21.3L        ₹ 15.0L  \n",
       "3        ₹ 22.0L        ₹ 15.0L  \n",
       "4        ₹ 20.5L        ₹ 13.5L  \n",
       "5        ₹ 18.5L        ₹ 13.5L  \n",
       "6        ₹ 21.0L        ₹ 12.7L  \n",
       "7        ₹ 15.0L        ₹ 12.4L  \n",
       "8        ₹ 21.5L        ₹ 11.7L  \n",
       "9        ₹ 20.5L        ₹ 11.2L  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "\n",
    "DS= pd.DataFrame({\"Title\":title,\"NoSalary\":nosalary,\"Experience\":exp,\"Minmum_Salary\":minsalary,\"Maxmium_Salary\":maxsalary,\"Average_Salary\":avgsalary})\n",
    "DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ef088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
